{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS\n",
    "import warnings\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.feature_selection import chi2, SelectKBest, SelectFdr, SelectFwe\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "#Facial Id, NoseX, NoseY, ChinX, ChinY, LEX, LER, REX, RER, LMX, LMY, RMX, RMY, Yaw, Pitch, Roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = \"/Users/anumehaagrawal/Documents/Course_Work/Emotion-Analysis-in-Multimodal-data/Combined/three_features_merged.csv\"\n",
    "y_data = \"/Users/anumehaagrawal/Documents/Course_Work/Emotion-Analysis-in-Multimodal-data/Combined/y-output - Sheet1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5.297315623</th>\n",
       "      <th>5.10622414</th>\n",
       "      <th>5.33300425</th>\n",
       "      <th>5.541379781</th>\n",
       "      <th>5.043890154</th>\n",
       "      <th>5.866118592</th>\n",
       "      <th>3.57615974</th>\n",
       "      <th>4.865589795</th>\n",
       "      <th>3.771664731</th>\n",
       "      <th>5.25478356</th>\n",
       "      <th>5.800467905</th>\n",
       "      <th>5.147909377</th>\n",
       "      <th>4.891580046</th>\n",
       "      <th>5.351075433</th>\n",
       "      <th>5.350759594</th>\n",
       "      <th>5.845226374</th>\n",
       "      <th>5.610512744</th>\n",
       "      <th>5.477533668</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>5.184594</td>\n",
       "      <td>4.961385</td>\n",
       "      <td>4.777814</td>\n",
       "      <td>5.913916</td>\n",
       "      <td>5.433575</td>\n",
       "      <td>5.939925</td>\n",
       "      <td>5.459425</td>\n",
       "      <td>4.720002</td>\n",
       "      <td>4.939240</td>\n",
       "      <td>5.433540</td>\n",
       "      <td>3.991149</td>\n",
       "      <td>5.285035</td>\n",
       "      <td>3.704121</td>\n",
       "      <td>5.882548</td>\n",
       "      <td>5.963594</td>\n",
       "      <td>5.939170</td>\n",
       "      <td>6.211949</td>\n",
       "      <td>5.305750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.106512</td>\n",
       "      <td>4.831482</td>\n",
       "      <td>4.860595</td>\n",
       "      <td>5.020385</td>\n",
       "      <td>4.648259</td>\n",
       "      <td>4.331805</td>\n",
       "      <td>4.194227</td>\n",
       "      <td>4.174891</td>\n",
       "      <td>3.920329</td>\n",
       "      <td>4.495375</td>\n",
       "      <td>5.027823</td>\n",
       "      <td>4.261988</td>\n",
       "      <td>4.826245</td>\n",
       "      <td>5.828977</td>\n",
       "      <td>5.824390</td>\n",
       "      <td>5.619420</td>\n",
       "      <td>5.371858</td>\n",
       "      <td>5.295977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>5.895206</td>\n",
       "      <td>5.952686</td>\n",
       "      <td>5.662050</td>\n",
       "      <td>5.573416</td>\n",
       "      <td>4.952103</td>\n",
       "      <td>5.876603</td>\n",
       "      <td>6.248633</td>\n",
       "      <td>4.811490</td>\n",
       "      <td>6.248145</td>\n",
       "      <td>5.354862</td>\n",
       "      <td>6.226922</td>\n",
       "      <td>5.328155</td>\n",
       "      <td>5.534318</td>\n",
       "      <td>6.654135</td>\n",
       "      <td>6.487857</td>\n",
       "      <td>6.168383</td>\n",
       "      <td>5.922735</td>\n",
       "      <td>6.436036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>4.581633</td>\n",
       "      <td>4.417816</td>\n",
       "      <td>5.108099</td>\n",
       "      <td>4.883979</td>\n",
       "      <td>4.622794</td>\n",
       "      <td>5.325157</td>\n",
       "      <td>5.164145</td>\n",
       "      <td>4.817828</td>\n",
       "      <td>5.274742</td>\n",
       "      <td>5.459018</td>\n",
       "      <td>5.503905</td>\n",
       "      <td>4.340535</td>\n",
       "      <td>4.802950</td>\n",
       "      <td>5.060182</td>\n",
       "      <td>5.211147</td>\n",
       "      <td>5.455035</td>\n",
       "      <td>5.272711</td>\n",
       "      <td>4.612804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>3.862214</td>\n",
       "      <td>3.560751</td>\n",
       "      <td>3.887543</td>\n",
       "      <td>4.701943</td>\n",
       "      <td>3.171457</td>\n",
       "      <td>5.222559</td>\n",
       "      <td>4.912748</td>\n",
       "      <td>4.644977</td>\n",
       "      <td>3.442679</td>\n",
       "      <td>4.771715</td>\n",
       "      <td>5.496765</td>\n",
       "      <td>3.615313</td>\n",
       "      <td>3.416008</td>\n",
       "      <td>5.383760</td>\n",
       "      <td>5.205279</td>\n",
       "      <td>4.882403</td>\n",
       "      <td>5.889864</td>\n",
       "      <td>3.564973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>3.770640</td>\n",
       "      <td>3.788818</td>\n",
       "      <td>3.778396</td>\n",
       "      <td>3.834715</td>\n",
       "      <td>3.125481</td>\n",
       "      <td>4.512165</td>\n",
       "      <td>4.104517</td>\n",
       "      <td>3.287912</td>\n",
       "      <td>3.816509</td>\n",
       "      <td>4.013969</td>\n",
       "      <td>6.075620</td>\n",
       "      <td>2.574769</td>\n",
       "      <td>4.039454</td>\n",
       "      <td>6.104773</td>\n",
       "      <td>6.038526</td>\n",
       "      <td>4.260712</td>\n",
       "      <td>5.285248</td>\n",
       "      <td>3.868875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>5.205623</td>\n",
       "      <td>5.022725</td>\n",
       "      <td>5.496662</td>\n",
       "      <td>5.374219</td>\n",
       "      <td>4.620666</td>\n",
       "      <td>4.959914</td>\n",
       "      <td>6.605750</td>\n",
       "      <td>4.274038</td>\n",
       "      <td>5.332428</td>\n",
       "      <td>6.523456</td>\n",
       "      <td>5.941232</td>\n",
       "      <td>4.180113</td>\n",
       "      <td>4.961768</td>\n",
       "      <td>5.205703</td>\n",
       "      <td>5.018364</td>\n",
       "      <td>6.021969</td>\n",
       "      <td>6.275558</td>\n",
       "      <td>4.422086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.190017</td>\n",
       "      <td>5.104413</td>\n",
       "      <td>5.362068</td>\n",
       "      <td>5.445291</td>\n",
       "      <td>4.500852</td>\n",
       "      <td>5.014553</td>\n",
       "      <td>5.442909</td>\n",
       "      <td>4.832982</td>\n",
       "      <td>4.958697</td>\n",
       "      <td>5.277959</td>\n",
       "      <td>6.255331</td>\n",
       "      <td>5.460708</td>\n",
       "      <td>5.011522</td>\n",
       "      <td>6.301353</td>\n",
       "      <td>6.107943</td>\n",
       "      <td>5.681897</td>\n",
       "      <td>6.093269</td>\n",
       "      <td>5.576444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.608315</td>\n",
       "      <td>3.295559</td>\n",
       "      <td>3.648575</td>\n",
       "      <td>3.494079</td>\n",
       "      <td>2.837466</td>\n",
       "      <td>3.709696</td>\n",
       "      <td>2.699609</td>\n",
       "      <td>3.573678</td>\n",
       "      <td>4.179493</td>\n",
       "      <td>3.367100</td>\n",
       "      <td>5.476332</td>\n",
       "      <td>2.289539</td>\n",
       "      <td>4.707548</td>\n",
       "      <td>6.052349</td>\n",
       "      <td>5.383244</td>\n",
       "      <td>4.191806</td>\n",
       "      <td>5.102513</td>\n",
       "      <td>3.706766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>5.399637</td>\n",
       "      <td>5.640185</td>\n",
       "      <td>5.658362</td>\n",
       "      <td>5.891752</td>\n",
       "      <td>5.354908</td>\n",
       "      <td>5.222134</td>\n",
       "      <td>6.184183</td>\n",
       "      <td>4.817828</td>\n",
       "      <td>4.912835</td>\n",
       "      <td>6.027221</td>\n",
       "      <td>6.130721</td>\n",
       "      <td>5.449248</td>\n",
       "      <td>5.730253</td>\n",
       "      <td>5.291514</td>\n",
       "      <td>5.120695</td>\n",
       "      <td>6.014407</td>\n",
       "      <td>6.529525</td>\n",
       "      <td>4.778745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     5.297315623  5.10622414  5.33300425  5.541379781  5.043890154  \\\n",
       "34      5.184594    4.961385    4.777814     5.913916     5.433575   \n",
       "3       5.106512    4.831482    4.860595     5.020385     4.648259   \n",
       "57      5.895206    5.952686    5.662050     5.573416     4.952103   \n",
       "125     4.581633    4.417816    5.108099     4.883979     4.622794   \n",
       "32      3.862214    3.560751    3.887543     4.701943     3.171457   \n",
       "..           ...         ...         ...          ...          ...   \n",
       "51      3.770640    3.788818    3.778396     3.834715     3.125481   \n",
       "110     5.205623    5.022725    5.496662     5.374219     4.620666   \n",
       "20      5.190017    5.104413    5.362068     5.445291     4.500852   \n",
       "120     3.608315    3.295559    3.648575     3.494079     2.837466   \n",
       "95      5.399637    5.640185    5.658362     5.891752     5.354908   \n",
       "\n",
       "     5.866118592  3.57615974  4.865589795  3.771664731  5.25478356  \\\n",
       "34      5.939925    5.459425     4.720002     4.939240    5.433540   \n",
       "3       4.331805    4.194227     4.174891     3.920329    4.495375   \n",
       "57      5.876603    6.248633     4.811490     6.248145    5.354862   \n",
       "125     5.325157    5.164145     4.817828     5.274742    5.459018   \n",
       "32      5.222559    4.912748     4.644977     3.442679    4.771715   \n",
       "..           ...         ...          ...          ...         ...   \n",
       "51      4.512165    4.104517     3.287912     3.816509    4.013969   \n",
       "110     4.959914    6.605750     4.274038     5.332428    6.523456   \n",
       "20      5.014553    5.442909     4.832982     4.958697    5.277959   \n",
       "120     3.709696    2.699609     3.573678     4.179493    3.367100   \n",
       "95      5.222134    6.184183     4.817828     4.912835    6.027221   \n",
       "\n",
       "     5.800467905  5.147909377  4.891580046  5.351075433  5.350759594  \\\n",
       "34      3.991149     5.285035     3.704121     5.882548     5.963594   \n",
       "3       5.027823     4.261988     4.826245     5.828977     5.824390   \n",
       "57      6.226922     5.328155     5.534318     6.654135     6.487857   \n",
       "125     5.503905     4.340535     4.802950     5.060182     5.211147   \n",
       "32      5.496765     3.615313     3.416008     5.383760     5.205279   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "51      6.075620     2.574769     4.039454     6.104773     6.038526   \n",
       "110     5.941232     4.180113     4.961768     5.205703     5.018364   \n",
       "20      6.255331     5.460708     5.011522     6.301353     6.107943   \n",
       "120     5.476332     2.289539     4.707548     6.052349     5.383244   \n",
       "95      6.130721     5.449248     5.730253     5.291514     5.120695   \n",
       "\n",
       "     5.845226374  5.610512744  5.477533668  \n",
       "34      5.939170     6.211949     5.305750  \n",
       "3       5.619420     5.371858     5.295977  \n",
       "57      6.168383     5.922735     6.436036  \n",
       "125     5.455035     5.272711     4.612804  \n",
       "32      4.882403     5.889864     3.564973  \n",
       "..           ...          ...          ...  \n",
       "51      4.260712     5.285248     3.868875  \n",
       "110     6.021969     6.275558     4.422086  \n",
       "20      5.681897     6.093269     5.576444  \n",
       "120     4.191806     5.102513     3.706766  \n",
       "95      6.014407     6.529525     4.778745  \n",
       "\n",
       "[137 rows x 18 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_df = pd.read_csv(x_data)\n",
    "y_df = pd.read_csv(y_data)\n",
    "\n",
    "y_df = y_df.astype(float, errors='ignore')\n",
    "x_df = x_df.drop(x_df.columns[0], axis=1)\n",
    "y_df = y_df.drop(y_df.columns[0], axis=1)\n",
    "y_df = y_df.drop(y_df.columns[-1], axis=1)\n",
    "x_df = x_df.abs()\n",
    "df = pd.concat([x_df,y_df],axis =1)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "x_df = df.iloc[:,:99]\n",
    "y_df = df.iloc[:,99:]\n",
    "y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(dataset, threshold):\n",
    "    col_corr = set()  # Set of all the names of correlated columns\n",
    "    corr = dataset.corr()\n",
    "    \n",
    "    for i in range(len(corr.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
    "                colname = corr.columns[i]  # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "    return col_corr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# clf = RandomForestClassifier(random_state=42, max_features='auto', n_estimators= 200, max_depth=8, criterion='gini')\n",
    "# efs1 = EFS(clf, \n",
    "#            min_features=1,\n",
    "#            max_features=10,\n",
    "#            scoring='accuracy',\n",
    "#            print_progress=True,\n",
    "#            cv=5)\n",
    "\n",
    "\n",
    "# efs1 = efs1.fit(X_train, y_train[y_train.columns[0:1]])\n",
    "# print('Best accuracy score: %.2f' % efs1.best_score_)\n",
    "    \n",
    "from sklearn import preprocessing\n",
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"weighted\"):\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "    return roc_auc_score(y_test, y_pred, average=average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-536e12247a71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorr_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorr_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0my_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_class_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_y_class_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mDOUBLE\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_validate_y_class_weight\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_y_class_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    167\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[1;32m    168\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "\n",
    "threshold = 0.5\n",
    "selected_features = [] \n",
    "clf = RandomForestClassifier(random_state=20, max_features=10, n_estimators= 100, max_depth=7, criterion='entropy')\n",
    "#clf = SVC(decision_function_shape='ovo')\n",
    "#clf = linear_model.MultiTaskLasso(alpha=0.4,random_state=42)\n",
    "for i in range(len(y_df.columns)):\n",
    "    \n",
    "    selector = SelectFwe(alpha =40.0)\n",
    "    X_new = selector.fit_transform(x_df,  y_df[y_df.columns[i:i+1]])\n",
    "    X = pd.DataFrame(X_new)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_df, test_size=0.2, random_state=20)\n",
    "    corr_features = correlation(X_train, 0.8)\n",
    "    \n",
    "    X_train.drop(labels=corr_features, axis=1, inplace=True)\n",
    "    X_test.drop(labels=corr_features, axis=1, inplace=True)\n",
    "    clf.fit(X_train, y_train[y_train.columns[i:i+1]])\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_predict = pd.DataFrame(y_pred)\n",
    "    #macro_roc_auc_ovo = multiclass_roc_auc_score(y_test[y_test.columns[i:i+1]],y_predict)\n",
    "    #print(macro_roc_auc_ovo)\n",
    "    print(accuracy_score(y_test[y_test.columns[i:i+1]],y_predict))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: (array([[0.61511111],\n       [0.74740741],\n       [0.79204938],\n       [0.92819753],\n       [0.95297907],\n       [0.74018795],\n       [0.66602469],\n       [0.85402469],\n       [0.79204938],\n       [0.93649383],\n       [0.80706173],\n       [0.81417284],\n       [0.61940741],\n       [0.87106173],\n       [0.67481481],\n       [0.76079012],\n       [0.86430041],\n       [0.58138272],\n       [0.90883951],\n       [0.67234568],\n       [1.11535802],\n       [0.69012346],\n       [0.80587654],\n       [0.70637037],\n       [0.853003  ],\n       [0.84118519],\n       [0.81215441],\n       [0.58602469],\n       [0.68278867],\n       [0.52296296],\n       [0.80464198],\n       [0.68287037],\n       [0.64222222],\n       [0.72350617],\n       [0.77081481],\n       [0.71135802],\n       [0.75051852],\n       [1.03461728],\n       [0.59392593],\n       [0.54251852],\n       [0.80944713],\n       [0.82296296],\n       [0.97733333],\n       [0.82958025],\n       [0.82384259],\n       [0.87130864],\n       [1.10165485],\n       [0.80982716],\n       [0.71520988],\n       [0.76079012],\n       [0.7802963 ],\n       [0.82197531],\n       [0.70790123],\n       [0.90785185],\n       [0.68014815],\n       [0.70474074],\n       [0.69061728],\n       [0.59293827],\n       [0.76148148],\n       [1.07358025],\n       [0.72365432],\n       [0.83002469],\n       [0.47644444],\n       [0.92201058],\n       [0.71437037],\n       [0.85916049],\n       [0.7057284 ],\n       [0.54034568],\n       [0.90375309],\n       [0.71135802],\n       [0.94767784],\n       [1.04780247],\n       [0.77068336],\n       [0.75817284],\n       [0.87259259],\n       [0.94153086],\n       [0.77718519],\n       [0.8505679 ],\n       [0.91744498],\n       [0.43945679],\n       [0.85522634],\n       [0.79245283],\n       [0.95017284],\n       [0.92316049],\n       [0.83110096],\n       [0.2531358 ],\n       [0.74044444],\n       [0.48316049],\n       [0.67397531],\n       [0.78217284],\n       [0.92054321],\n       [1.08834423],\n       [0.60019753],\n       [0.84064198],\n       [0.78903704],\n       [0.97580247],\n       [0.63669136],\n       [0.65802469],\n       [0.73861728],\n       [0.49102132],\n       [0.76651852],\n       [0.56101101],\n       [0.81787654],\n       [0.95017284],\n       [0.6486987 ],\n       [0.35682698],\n       [0.77748148],\n       [1.1361454 ],\n       [1.21012346],\n       [0.79131944],\n       [0.55575309],\n       [0.76508642],\n       [0.58894961],\n       [0.83693827],\n       [0.75041975],\n       [0.67051852],\n       [0.7362963 ],\n       [0.78131054],\n       [0.69035494],\n       [0.77940741],\n       [0.94696296],\n       [0.95817284],\n       [0.84834568],\n       [0.73190123],\n       [0.8122963 ],\n       [0.68567901],\n       [0.62982716],\n       [0.68098765],\n       [0.81669136],\n       [0.90192593],\n       [0.562849  ],\n       [0.58028322],\n       [0.82430882],\n       [0.92820513],\n       [0.79575309],\n       [0.60533333],\n       [0.72372517]]),)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-16e8eabb00d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mselector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSelectFdr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchi2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m11.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mX_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_df\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0my_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0mscore_func_ret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_func_ret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpvalues_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_func_ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py\u001b[0m in \u001b[0;36mchi2\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input X must be non-negative.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0mShape\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbinary\u001b[0m \u001b[0mproblems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \"\"\"\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_input_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0m_unique_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FN_UNIQUE_LABELS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_unique_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mys_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: (array([[0.61511111],\n       [0.74740741],\n       [0.79204938],\n       [0.92819753],\n       [0.95297907],\n       [0.74018795],\n       [0.66602469],\n       [0.85402469],\n       [0.79204938],\n       [0.93649383],\n       [0.80706173],\n       [0.81417284],\n       [0.61940741],\n       [0.87106173],\n       [0.67481481],\n       [0.76079012],\n       [0.86430041],\n       [0.58138272],\n       [0.90883951],\n       [0.67234568],\n       [1.11535802],\n       [0.69012346],\n       [0.80587654],\n       [0.70637037],\n       [0.853003  ],\n       [0.84118519],\n       [0.81215441],\n       [0.58602469],\n       [0.68278867],\n       [0.52296296],\n       [0.80464198],\n       [0.68287037],\n       [0.64222222],\n       [0.72350617],\n       [0.77081481],\n       [0.71135802],\n       [0.75051852],\n       [1.03461728],\n       [0.59392593],\n       [0.54251852],\n       [0.80944713],\n       [0.82296296],\n       [0.97733333],\n       [0.82958025],\n       [0.82384259],\n       [0.87130864],\n       [1.10165485],\n       [0.80982716],\n       [0.71520988],\n       [0.76079012],\n       [0.7802963 ],\n       [0.82197531],\n       [0.70790123],\n       [0.90785185],\n       [0.68014815],\n       [0.70474074],\n       [0.69061728],\n       [0.59293827],\n       [0.76148148],\n       [1.07358025],\n       [0.72365432],\n       [0.83002469],\n       [0.47644444],\n       [0.92201058],\n       [0.71437037],\n       [0.85916049],\n       [0.7057284 ],\n       [0.54034568],\n       [0.90375309],\n       [0.71135802],\n       [0.94767784],\n       [1.04780247],\n       [0.77068336],\n       [0.75817284],\n       [0.87259259],\n       [0.94153086],\n       [0.77718519],\n       [0.8505679 ],\n       [0.91744498],\n       [0.43945679],\n       [0.85522634],\n       [0.79245283],\n       [0.95017284],\n       [0.92316049],\n       [0.83110096],\n       [0.2531358 ],\n       [0.74044444],\n       [0.48316049],\n       [0.67397531],\n       [0.78217284],\n       [0.92054321],\n       [1.08834423],\n       [0.60019753],\n       [0.84064198],\n       [0.78903704],\n       [0.97580247],\n       [0.63669136],\n       [0.65802469],\n       [0.73861728],\n       [0.49102132],\n       [0.76651852],\n       [0.56101101],\n       [0.81787654],\n       [0.95017284],\n       [0.6486987 ],\n       [0.35682698],\n       [0.77748148],\n       [1.1361454 ],\n       [1.21012346],\n       [0.79131944],\n       [0.55575309],\n       [0.76508642],\n       [0.58894961],\n       [0.83693827],\n       [0.75041975],\n       [0.67051852],\n       [0.7362963 ],\n       [0.78131054],\n       [0.69035494],\n       [0.77940741],\n       [0.94696296],\n       [0.95817284],\n       [0.84834568],\n       [0.73190123],\n       [0.8122963 ],\n       [0.68567901],\n       [0.62982716],\n       [0.68098765],\n       [0.81669136],\n       [0.90192593],\n       [0.562849  ],\n       [0.58028322],\n       [0.82430882],\n       [0.92820513],\n       [0.79575309],\n       [0.60533333],\n       [0.72372517]]),)"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "threshold = 0.6\n",
    "from sklearn.preprocessing import StandardScaler  # doctest: +SKIP\n",
    "\n",
    "clf = RandomForestClassifier(random_state=20, max_features=10, n_estimators= 100, max_depth=7, criterion='entropy')\n",
    "for i in range(len(y_df.columns)):\n",
    "    \n",
    "    selector = SelectFdr(chi2, alpha =11.0)\n",
    "    X_new = selector.fit_transform(x_df,  y_df[y_df.columns[i:i+1]])\n",
    "    X = pd.DataFrame(X_new)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_df, test_size=0.2, random_state=42)\n",
    "    scaler = StandardScaler()  # doctest: +SKIP\n",
    "    scaler.fit(X_train)  # doctest: +SKIP\n",
    "    X_train = scaler.transform(X_train)  # doctest: +SKIP\n",
    "    X_test = scaler.transform(X_test) \n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "    corr_features = correlation(X_train, 0.8)\n",
    "    X_train.drop(labels=corr_features, axis=1, inplace=True)\n",
    "    X_test.drop(labels=corr_features, axis=1, inplace=True)\n",
    "    clf.fit(X_train, y_train[y_train.columns[i:i+1]])\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_predict = pd.DataFrame(y_pred)\n",
    "    #macro_roc_auc_ovo = multiclass_roc_auc_score(y_test[y_test.columns[i:i+1]],y_predict)\n",
    "    #print(macro_roc_auc_ovo)\n",
    "    print(accuracy_score(y_test[y_test.columns[i:i+1]],y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4457326892109501\n",
      "0.3950080515297906\n",
      "0.3798711755233495\n",
      "0.5763285024154589\n",
      "0.34251207729468597\n",
      "0.5181964573268921\n",
      "0.3869565217391305\n",
      "0.8167471819645732\n",
      "0.27713365539452495\n",
      "0.4090177133655395\n",
      "0.6714975845410628\n",
      "0.3289855072463768\n",
      "0.39388083735909823\n",
      "0.6492753623188405\n",
      "0.6349436392914654\n",
      "0.677938808373591\n",
      "0.4450885668276973\n",
      "0.29935587761674715\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "threshold = 0.6\n",
    "from sklearn.preprocessing import StandardScaler  # doctest: +SKIP\n",
    "from sklearn.model_selection import KFold \n",
    "kf = KFold(3,True,4) \n",
    "clf = RandomForestClassifier( random_state= 10,max_features=10, n_estimators= 100, max_depth=9, criterion='entropy')\n",
    "for i in range(len(y_df.columns)):\n",
    "    selector = SelectFdr(chi2, alpha =9.0)\n",
    "    X_new = selector.fit_transform(x_df,  y_df[y_df.columns[i:i+1]])\n",
    "    X = pd.DataFrame(X_new)\n",
    "    summ =0\n",
    "    count =0\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        count = count+1\n",
    "        X_train, X_test = X.loc[train_index], X.loc[val_index]\n",
    "        y_train, y_test = y_df.loc[train_index], y_df.loc[val_index]\n",
    "        \n",
    "        scaler = StandardScaler()  # doctest: +SKIP\n",
    "        scaler.fit(X_train)  # doctest: +SKIP\n",
    "        X_train = scaler.transform(X_train)  # doctest: +SKIP\n",
    "        X_test = scaler.transform(X_test) \n",
    "        X_train = pd.DataFrame(X_train)\n",
    "        X_test = pd.DataFrame(X_test)\n",
    "        corr_features = correlation(X_train, 0.8)\n",
    "        X_train.drop(labels=corr_features, axis=1, inplace=True)\n",
    "        X_test.drop(labels=corr_features, axis=1, inplace=True)\n",
    "        clf.fit(X_train, y_train[y_train.columns[i:i+1]])\n",
    "        y_pred = clf.predict(X_test)\n",
    "        y_predict = pd.DataFrame(y_pred)\n",
    "        #macro_roc_auc_ovo = multiclass_roc_auc_score(y_test[y_test.columns[i:i+1]],y_predict)\n",
    "        #print(macro_roc_auc_ovo)\n",
    "        summ = summ + accuracy_score(y_test[y_test.columns[i:i+1]],y_predict)\n",
    "    print(summ/count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=6)]: Done 202 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=6)]: Done 360 out of 360 | elapsed:   12.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-f56e95353dd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorr_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorr_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0my_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 667\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "threshold = 0.6\n",
    "from sklearn.preprocessing import StandardScaler  # doctest: +SKIP\n",
    "param_grid = {\n",
    "    'bootstrap': [True,False],\n",
    "    'max_depth': [80, 90, 100],\n",
    "    'max_features': [2, 6, 10, 9],\n",
    "     'min_samples_leaf': [3, 4, 5],\n",
    "#     'min_samples_split': [8, 10, 12],\n",
    "#      'n_estimators': [10, 20, 100, 200]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "clf = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = 6, verbose = 2)\n",
    "#clf = RandomForestClassifier(random_state=20, max_features=10, n_estimators= 100, max_depth=7, criterion='entropy')\n",
    "for i in range(len(y_df.columns)):\n",
    "    \n",
    "    selector = SelectFdr(chi2, alpha =8)\n",
    "    X_new = selector.fit_transform(x_df,  y_df[y_df.columns[i:i+1]])\n",
    "    X = pd.DataFrame(X_new)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_df, y_df, test_size=0.2, random_state=56)\n",
    "    scaler = StandardScaler()  # doctest: +SKIP\n",
    "    scaler.fit(X_train)  # doctest: +SKIP\n",
    "    X_train = scaler.transform(X_train)  # doctest: +SKIP\n",
    "    X_test = scaler.transform(X_test) \n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "    corr_features = correlation(X_train, 0.65)\n",
    "    X_train.drop(labels=corr_features, axis=1, inplace=True)\n",
    "    X_test.drop(labels=corr_features, axis=1, inplace=True)\n",
    "    clf.fit(X_train, y_train[y_train.columns[i:i+1]])\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_predict = pd.DataFrame(y_pred)\n",
    "    #macro_roc_auc_ovo = multiclass_roc_auc_score(y_test[y_test.columns[i:i+1]],y_predict)\n",
    "    #print(macro_roc_auc_ovo)\n",
    "    print(accuracy_score(y_test[y_test.columns[i:i+1]],y_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.6071428571428571\n",
    "0.42857142857142855\n",
    "0.4642857142857143\n",
    "0.6071428571428571\n",
    "0.39285714285714285\n",
    "0.5714285714285714\n",
    "0.4642857142857143\n",
    "0.9642857142857143\n",
    "0.32142857142857145\n",
    "0.39285714285714285\n",
    "0.8214285714285714\n",
    "0.42857142857142855\n",
    "0.42857142857142855\n",
    "0.6428571428571429\n",
    "0.7142857142857143\n",
    "0.6071428571428571\n",
    "0.35714285714285715\n",
    "0.6071428571428571"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(m,X,y):\n",
    "    yhat = m.predict(X)\n",
    "    print(yhat)\n",
    "    SS_Residual = sum((y-yhat)**2)\n",
    "    SS_Total = sum((y-np.mean(y))**2)\n",
    "    r_squared = 1 - (float(SS_Residual))/SS_Total\n",
    "    adj_r_squared = 1 - (1-r_squared)*(len(y)-1)/(len(y)-X.shape[1]-1)\n",
    "    return r_squared,adj_r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.297315623    146.782207\n",
      "dtype: float64 0    143.788368\n",
      "dtype: float64\n",
      "-------------------\n",
      "5.10622414    141.625051\n",
      "dtype: float64 0    133.671302\n",
      "dtype: float64\n",
      "-------------------\n",
      "5.33300425    139.27781\n",
      "dtype: float64 0    142.823183\n",
      "dtype: float64\n",
      "-------------------\n",
      "5.541379781    153.314605\n",
      "dtype: float64 0    150.476389\n",
      "dtype: float64\n",
      "-------------------\n",
      "5.043890154    138.863209\n",
      "dtype: float64 0    135.271895\n",
      "dtype: float64\n",
      "-------------------\n",
      "5.866118592    152.471376\n",
      "dtype: float64 0    156.830639\n",
      "dtype: float64\n",
      "-------------------\n",
      "3.57615974    146.453654\n",
      "dtype: float64 0    149.364771\n",
      "dtype: float64\n",
      "-------------------\n",
      "4.865589795    131.388855\n",
      "dtype: float64 0    129.592713\n",
      "dtype: float64\n",
      "-------------------\n",
      "3.771664731    118.321698\n",
      "dtype: float64 0    122.052537\n",
      "dtype: float64\n",
      "-------------------\n",
      "5.25478356    147.930427\n",
      "dtype: float64 0    154.315796\n",
      "dtype: float64\n",
      "-------------------\n",
      "5.800467905    156.979808\n",
      "dtype: float64 0    156.986392\n",
      "dtype: float64\n",
      "-------------------\n",
      "5.147909377    139.6206\n",
      "dtype: float64 0    134.532393\n",
      "dtype: float64\n",
      "-------------------\n",
      "4.891580046    131.846434\n",
      "dtype: float64 0    136.009724\n",
      "dtype: float64\n",
      "-------------------\n",
      "5.351075433    153.838155\n",
      "dtype: float64 0    151.497499\n",
      "dtype: float64\n",
      "-------------------\n",
      "5.350759594    153.804237\n",
      "dtype: float64 0    150.888636\n",
      "dtype: float64\n",
      "-------------------\n",
      "5.845226374    161.974189\n",
      "dtype: float64 0    154.488265\n",
      "dtype: float64\n",
      "-------------------\n",
      "5.610512744    166.685379\n",
      "dtype: float64 0    163.743305\n",
      "dtype: float64\n",
      "-------------------\n",
      "5.477533668    149.74487\n",
      "dtype: float64 0    139.727909\n",
      "dtype: float64\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler  # doctest: +SKIP\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "param_grid = {\n",
    "    'C': [0.5, 1.0, 2.0],\n",
    "    'epsilon': [0.1,0.2,0.5, 0.9],\n",
    "    \n",
    "#     'min_samples_split': [8, 10, 12],\n",
    "#      'n_estimators': [10, 20, 100, 200]\n",
    "}\n",
    "# Create a based model\n",
    "clf = dtree1 = DecisionTreeRegressor(max_depth=2)\n",
    "# Instantiate the grid search model\n",
    "#clf = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 5, n_jobs = 6, verbose = 2)\n",
    "#clf = RandomForestClassifier(random_state=20, max_features=10, n_estimators= 100, max_depth=7, criterion='entropy')\n",
    "X = x_df\n",
    "for i in range(len(y_df.columns)):\n",
    "    \n",
    "#     reg = LassoCV()\n",
    "#     reg.fit(x_df, y_df[y_df.columns[i:i+1]])\n",
    "#     print(\"Best alpha using built-in LassoCV: %f\" % reg.alpha_)\n",
    "#     print(\"Best score using built-in LassoCV: %f\" %reg.score(x_df, y_df[y_df.columns[i:i+1]]))\n",
    "#     print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")\n",
    "#     coef = pd.Series(reg.coef_, index = x_df.columns)\n",
    "#     imp_coef = coef.sort_values()\n",
    "#     print(imp_coef)\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_df,y_df[y_df.columns[i:i+1]], test_size=0.2)\n",
    "    \n",
    "    scaler = StandardScaler()  # doctest: +SKIP\n",
    "    scaler.fit(X_train)  # doctest: +SKIP\n",
    "    X_train = scaler.transform(X_train)  # doctest: +SKIP\n",
    "    X_test = scaler.transform(X_test) \n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_predict = pd.DataFrame(y_pred)\n",
    "    y_test = pd.DataFrame(y_test)\n",
    "#     print(y_predict)\n",
    "#     print(y_test)\n",
    "    print(y_test.sum(), y_predict.sum())\n",
    "    #print(r2_score(y_test, y_pred))\n",
    "    print(\"-------------------\")\n",
    "    \n",
    "#     macro_roc_auc_ovo = multiclass_roc_auc_score(y_test,y_predict)\n",
    "#     print(macro_roc_auc_ovo)\n",
    "   \n",
    "#     print(clf.score(X_test,y_test))\n",
    "#     x_df = X\n",
    "#     cols = list(x_df.columns)\n",
    "#     model = LinearRegression()\n",
    "#     #Initializing RFE model\n",
    "#     rfe = RFE(model, 10)             \n",
    "#     #Transforming data using RFE\n",
    "#     X_rfe = rfe.fit_transform(x_df,y_df[y_df.columns[i:i+1]])  \n",
    "#     #Fitting the data to model\n",
    "#     model.fit(X_rfe,y_df[y_df.columns[i:i+1]])              \n",
    "#     temp = pd.Series(rfe.support_,index = cols)\n",
    "#     selected_features_rfe = temp[temp==True].index\n",
    "#     print(selected_features_rfe)\n",
    "#     for i in x_df.columns:\n",
    "#         if i not in selected_features_rfe:\n",
    "#             x_df = x_df.drop(i, axis=1)\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(x_df,y_df[y_df.columns[i:i+1]], test_size=0.2)\n",
    "#     scaler = StandardScaler()  # doctest: +SKIP\n",
    "#     scaler.fit(X_train)  # doctest: +SKIP\n",
    "#     X_train = scaler.transform(X_train)  # doctest: +SKIP\n",
    "#     X_test = scaler.transform(X_test) \n",
    "#     X_train = pd.DataFrame(X_train)\n",
    "#     X_test = pd.DataFrame(X_test)\n",
    "    \n",
    "#     clf.fit(X_train, y_train)\n",
    "#     y_pred = clf.predict(X_test)\n",
    "#     y_predict = pd.DataFrame(y_pred)\n",
    "    \n",
    "# #     macro_roc_auc_ovo = multiclass_roc_auc_score(y_test,y_predict)\n",
    "# #     print(macro_roc_auc_ovo)\n",
    "#     #print(accuracy_score(y_test,y_predict))\n",
    "#     print(clf.score(X_test,y_test))\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5.297315623</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>5.355869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>5.293564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.190017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>5.954057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>4.727263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.538979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>5.038526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>5.415966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>4.760002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>4.236546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>4.864386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.608315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>5.846003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.725115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>4.642314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>5.784742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>5.382496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.457670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>5.157982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>5.319215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>4.581633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>5.770041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>5.771733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>4.057952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>4.738970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>4.789387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>4.865379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>5.380115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     5.297315623\n",
       "70      5.355869\n",
       "89      5.293564\n",
       "20      5.190017\n",
       "64      5.954057\n",
       "54      4.727263\n",
       "100     5.538979\n",
       "8       5.038526\n",
       "107     5.415966\n",
       "121     4.760002\n",
       "14      4.236546\n",
       "53      4.864386\n",
       "120     3.608315\n",
       "63      5.846003\n",
       "6       4.725115\n",
       "59      4.642314\n",
       "130     5.784742\n",
       "94      5.382496\n",
       "2       5.457670\n",
       "58      5.157982\n",
       "74      5.319215\n",
       "125     4.581633\n",
       "104     5.770041\n",
       "17      5.771733\n",
       "105     4.057952\n",
       "47      4.738970\n",
       "61      4.789387\n",
       "43      4.865379\n",
       "129     5.380115"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
