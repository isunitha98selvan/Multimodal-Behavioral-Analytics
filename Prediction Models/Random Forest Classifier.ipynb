{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS\n",
    "import warnings\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.feature_selection import chi2, SelectKBest, SelectFdr, SelectFwe\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = \"/Users/anumehaagrawal/Documents/Course_Work/Emotion-Analysis-in-Multimodal-data/Combined/Lexical + audio - three_features_merged.csv\"\n",
    "y_data = \"/Users/anumehaagrawal/Documents/Course_Work/Emotion-Analysis-in-Multimodal-data/Combined/y-output - Sheet1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0003103610031</th>\n",
       "      <th>58.89807156</th>\n",
       "      <th>196.992</th>\n",
       "      <th>142.1601663</th>\n",
       "      <th>74.30483534</th>\n",
       "      <th>599.939292</th>\n",
       "      <th>0.07841212505</th>\n",
       "      <th>0.002936686887</th>\n",
       "      <th>3.097412401</th>\n",
       "      <th>0.1709953368</th>\n",
       "      <th>...</th>\n",
       "      <th>609</th>\n",
       "      <th>284</th>\n",
       "      <th>3.091496101</th>\n",
       "      <th>1.441682911</th>\n",
       "      <th>8</th>\n",
       "      <th>0.531373</th>\n",
       "      <th>0.520348</th>\n",
       "      <th>0.708033</th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>60.121939</td>\n",
       "      <td>426.000</td>\n",
       "      <td>115.346030</td>\n",
       "      <td>71.907626</td>\n",
       "      <td>559.165817</td>\n",
       "      <td>0.088106</td>\n",
       "      <td>0.003644</td>\n",
       "      <td>3.098069</td>\n",
       "      <td>0.167862</td>\n",
       "      <td>...</td>\n",
       "      <td>1113.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>2.612676</td>\n",
       "      <td>0.863850</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.642117</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.651181</td>\n",
       "      <td>0.606895</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>55.265210</td>\n",
       "      <td>271.992</td>\n",
       "      <td>190.902445</td>\n",
       "      <td>71.030606</td>\n",
       "      <td>593.526919</td>\n",
       "      <td>0.114184</td>\n",
       "      <td>0.002480</td>\n",
       "      <td>3.134633</td>\n",
       "      <td>0.202736</td>\n",
       "      <td>...</td>\n",
       "      <td>741.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>2.724345</td>\n",
       "      <td>1.058855</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.606516</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.620860</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>57.028214</td>\n",
       "      <td>204.984</td>\n",
       "      <td>186.773508</td>\n",
       "      <td>72.728255</td>\n",
       "      <td>586.069219</td>\n",
       "      <td>0.089705</td>\n",
       "      <td>0.001364</td>\n",
       "      <td>3.139515</td>\n",
       "      <td>0.195331</td>\n",
       "      <td>...</td>\n",
       "      <td>714.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>3.483199</td>\n",
       "      <td>1.341568</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.528993</td>\n",
       "      <td>0.521192</td>\n",
       "      <td>0.909287</td>\n",
       "      <td>0.514447</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>48.634250</td>\n",
       "      <td>294.000</td>\n",
       "      <td>186.221891</td>\n",
       "      <td>72.576028</td>\n",
       "      <td>545.329312</td>\n",
       "      <td>0.112451</td>\n",
       "      <td>0.003005</td>\n",
       "      <td>3.136228</td>\n",
       "      <td>0.227116</td>\n",
       "      <td>...</td>\n",
       "      <td>644.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>2.190476</td>\n",
       "      <td>0.884354</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.574884</td>\n",
       "      <td>0.510653</td>\n",
       "      <td>0.709780</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>57.741340</td>\n",
       "      <td>246.000</td>\n",
       "      <td>195.292435</td>\n",
       "      <td>72.860039</td>\n",
       "      <td>511.041246</td>\n",
       "      <td>0.106836</td>\n",
       "      <td>0.002307</td>\n",
       "      <td>3.122065</td>\n",
       "      <td>0.213910</td>\n",
       "      <td>...</td>\n",
       "      <td>612.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>2.487805</td>\n",
       "      <td>1.089431</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.599124</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.660757</td>\n",
       "      <td>0.549712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>52.423892</td>\n",
       "      <td>408.000</td>\n",
       "      <td>225.065918</td>\n",
       "      <td>71.466905</td>\n",
       "      <td>597.463942</td>\n",
       "      <td>0.166549</td>\n",
       "      <td>0.001616</td>\n",
       "      <td>3.166655</td>\n",
       "      <td>0.233252</td>\n",
       "      <td>...</td>\n",
       "      <td>513.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>1.257353</td>\n",
       "      <td>0.563725</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.588511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.813839</td>\n",
       "      <td>0.576384</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>56.737974</td>\n",
       "      <td>540.120</td>\n",
       "      <td>225.672808</td>\n",
       "      <td>79.112283</td>\n",
       "      <td>588.757340</td>\n",
       "      <td>0.111539</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>3.146009</td>\n",
       "      <td>0.206337</td>\n",
       "      <td>...</td>\n",
       "      <td>889.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>1.645931</td>\n",
       "      <td>0.594312</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.655967</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.794747</td>\n",
       "      <td>0.611884</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>54.647290</td>\n",
       "      <td>626.712</td>\n",
       "      <td>131.393269</td>\n",
       "      <td>72.401717</td>\n",
       "      <td>593.077505</td>\n",
       "      <td>0.137905</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>3.106303</td>\n",
       "      <td>0.204870</td>\n",
       "      <td>...</td>\n",
       "      <td>1222.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>1.949859</td>\n",
       "      <td>0.622295</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.611179</td>\n",
       "      <td>0.508575</td>\n",
       "      <td>0.953332</td>\n",
       "      <td>0.684415</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>56.877320</td>\n",
       "      <td>606.168</td>\n",
       "      <td>142.195172</td>\n",
       "      <td>66.336648</td>\n",
       "      <td>599.357254</td>\n",
       "      <td>0.094506</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>3.111328</td>\n",
       "      <td>0.194756</td>\n",
       "      <td>...</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>357.0</td>\n",
       "      <td>1.888915</td>\n",
       "      <td>0.588946</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.603404</td>\n",
       "      <td>0.502010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>57.818452</td>\n",
       "      <td>619.704</td>\n",
       "      <td>153.563205</td>\n",
       "      <td>74.999405</td>\n",
       "      <td>579.860997</td>\n",
       "      <td>0.116358</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>3.128030</td>\n",
       "      <td>0.201127</td>\n",
       "      <td>...</td>\n",
       "      <td>1238.0</td>\n",
       "      <td>394.0</td>\n",
       "      <td>1.997728</td>\n",
       "      <td>0.635787</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.617984</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.817721</td>\n",
       "      <td>0.614093</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows Ã— 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0.0003103610031  58.89807156  196.992  142.1601663  74.30483534  \\\n",
       "0           0.000411    60.121939  426.000   115.346030    71.907626   \n",
       "1           0.000134    55.265210  271.992   190.902445    71.030606   \n",
       "2           0.000202    57.028214  204.984   186.773508    72.728255   \n",
       "3           0.000029    48.634250  294.000   186.221891    72.576028   \n",
       "4           0.000238    57.741340  246.000   195.292435    72.860039   \n",
       "..               ...          ...      ...          ...          ...   \n",
       "132         0.000070    52.423892  408.000   225.065918    71.466905   \n",
       "133         0.000189    56.737974  540.120   225.672808    79.112283   \n",
       "134         0.000117    54.647290  626.712   131.393269    72.401717   \n",
       "135         0.000195    56.877320  606.168   142.195172    66.336648   \n",
       "136         0.000242    57.818452  619.704   153.563205    74.999405   \n",
       "\n",
       "     599.939292  0.07841212505  0.002936686887  3.097412401  0.1709953368  \\\n",
       "0    559.165817       0.088106        0.003644     3.098069      0.167862   \n",
       "1    593.526919       0.114184        0.002480     3.134633      0.202736   \n",
       "2    586.069219       0.089705        0.001364     3.139515      0.195331   \n",
       "3    545.329312       0.112451        0.003005     3.136228      0.227116   \n",
       "4    511.041246       0.106836        0.002307     3.122065      0.213910   \n",
       "..          ...            ...             ...          ...           ...   \n",
       "132  597.463942       0.166549        0.001616     3.166655      0.233252   \n",
       "133  588.757340       0.111539        0.000200     3.146009      0.206337   \n",
       "134  593.077505       0.137905        0.000200     3.106303      0.204870   \n",
       "135  599.357254       0.094506        0.000928     3.111328      0.194756   \n",
       "136  579.860997       0.116358        0.000475     3.128030      0.201127   \n",
       "\n",
       "     ...     609    284  3.091496101  1.441682911     8  0.531373  0.520348  \\\n",
       "0    ...  1113.0  368.0     2.612676     0.863850  75.0  0.642117  0.000000   \n",
       "1    ...   741.0  288.0     2.724345     1.058855  13.0  0.606516  0.000000   \n",
       "2    ...   714.0  275.0     3.483199     1.341568   7.0  0.528993  0.521192   \n",
       "3    ...   644.0  260.0     2.190476     0.884354  21.0  0.574884  0.510653   \n",
       "4    ...   612.0  268.0     2.487805     1.089431   5.0  0.599124  0.000000   \n",
       "..   ...     ...    ...          ...          ...   ...       ...       ...   \n",
       "132  ...   513.0  230.0     1.257353     0.563725  19.0  0.588511  0.000000   \n",
       "133  ...   889.0  321.0     1.645931     0.594312  21.0  0.655967  0.000000   \n",
       "134  ...  1222.0  390.0     1.949859     0.622295  65.0  0.611179  0.508575   \n",
       "135  ...  1145.0  357.0     1.888915     0.588946  21.0  0.603404  0.502010   \n",
       "136  ...  1238.0  394.0     1.997728     0.635787  37.0  0.617984  0.000000   \n",
       "\n",
       "     0.708033         0       0.1  \n",
       "0    0.651181  0.606895  0.000000  \n",
       "1    0.000000  0.620860  0.000000  \n",
       "2    0.909287  0.514447  0.000000  \n",
       "3    0.709780  0.000000  0.000000  \n",
       "4    0.000000  0.660757  0.549712  \n",
       "..        ...       ...       ...  \n",
       "132  0.813839  0.576384  0.000000  \n",
       "133  0.794747  0.611884  0.000000  \n",
       "134  0.953332  0.684415  0.000000  \n",
       "135  0.000000  0.000000  0.000000  \n",
       "136  0.817721  0.614093  0.000000  \n",
       "\n",
       "[137 rows x 85 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_df = pd.read_csv(x_data)\n",
    "y_df = pd.read_csv(y_data)\n",
    "\n",
    "y_df = y_df.astype(int, errors='ignore')\n",
    "x_df = x_df.drop(x_df.columns[0], axis=1)\n",
    "y_df = y_df.drop(y_df.columns[0], axis=1)\n",
    "y_df = y_df.drop(y_df.columns[-1], axis=1)\n",
    "x_df = x_df.abs()\n",
    "x_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(dataset, threshold):\n",
    "    col_corr = set()  # Set of all the names of correlated columns\n",
    "    corr = dataset.corr()\n",
    "    \n",
    "    for i in range(len(corr.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
    "                colname = corr.columns[i]  # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "    return col_corr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# clf = RandomForestClassifier(random_state=42, max_features='auto', n_estimators= 200, max_depth=8, criterion='gini')\n",
    "# efs1 = EFS(clf, \n",
    "#            min_features=1,\n",
    "#            max_features=10,\n",
    "#            scoring='accuracy',\n",
    "#            print_progress=True,\n",
    "#            cv=5)\n",
    "\n",
    "\n",
    "# efs1 = efs1.fit(X_train, y_train[y_train.columns[0:1]])\n",
    "# print('Best accuracy score: %.2f' % efs1.best_score_)\n",
    "    \n",
    "from sklearn import preprocessing\n",
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"weighted\"):\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "    return roc_auc_score(y_test, y_pred, average=average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6071428571428571\n",
      "0.39285714285714285\n",
      "0.42857142857142855\n",
      "0.75\n",
      "0.32142857142857145\n",
      "0.32142857142857145\n",
      "0.4642857142857143\n",
      "0.7857142857142857\n",
      "0.4642857142857143\n",
      "0.6071428571428571\n",
      "0.6785714285714286\n",
      "0.5\n",
      "0.42857142857142855\n",
      "0.7142857142857143\n",
      "0.75\n",
      "0.6785714285714286\n",
      "0.6071428571428571\n",
      "0.4642857142857143\n"
     ]
    }
   ],
   "source": [
    "\n",
    "threshold = 0.5\n",
    "selected_features = [] \n",
    "clf = RandomForestClassifier(random_state=20, max_features=10, n_estimators= 100, max_depth=7, criterion='entropy')\n",
    "#clf = SVC(decision_function_shape='ovo')\n",
    "#clf = linear_model.MultiTaskLasso(alpha=0.4,random_state=42)\n",
    "for i in range(len(y_df.columns)):\n",
    "    \n",
    "    selector = SelectFwe(alpha =40.0)\n",
    "    X_new = selector.fit_transform(x_df,  y_df[y_df.columns[i:i+1]])\n",
    "    X = pd.DataFrame(X_new)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_df, test_size=0.2, random_state=20)\n",
    "    corr_features = correlation(X_train, 0.8)\n",
    "    \n",
    "    X_train.drop(labels=corr_features, axis=1, inplace=True)\n",
    "    X_test.drop(labels=corr_features, axis=1, inplace=True)\n",
    "    clf.fit(X_train, y_train[y_train.columns[i:i+1]])\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_predict = pd.DataFrame(y_pred)\n",
    "    #macro_roc_auc_ovo = multiclass_roc_auc_score(y_test[y_test.columns[i:i+1]],y_predict)\n",
    "    #print(macro_roc_auc_ovo)\n",
    "    print(accuracy_score(y_test[y_test.columns[i:i+1]],y_predict))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6071428571428571\n",
      "0.6428571428571429\n",
      "0.5714285714285714\n",
      "0.6071428571428571\n",
      "0.42857142857142855\n",
      "0.5357142857142857\n",
      "0.32142857142857145\n",
      "0.9285714285714286\n",
      "0.2857142857142857\n",
      "0.42857142857142855\n",
      "0.8214285714285714\n",
      "0.5\n",
      "0.39285714285714285\n",
      "0.7857142857142857\n",
      "0.8214285714285714\n",
      "0.6071428571428571\n",
      "0.6428571428571429\n",
      "0.35714285714285715\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "threshold = 0.6\n",
    "from sklearn.preprocessing import StandardScaler  # doctest: +SKIP\n",
    "\n",
    "clf = RandomForestClassifier(random_state=20, max_features=10, n_estimators= 100, max_depth=7, criterion='entropy')\n",
    "for i in range(len(y_df.columns)):\n",
    "    \n",
    "    selector = SelectFdr(chi2, alpha =11.0)\n",
    "    X_new = selector.fit_transform(x_df,  y_df[y_df.columns[i:i+1]])\n",
    "    X = pd.DataFrame(X_new)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_df, test_size=0.2, random_state=42)\n",
    "    scaler = StandardScaler()  # doctest: +SKIP\n",
    "    scaler.fit(X_train)  # doctest: +SKIP\n",
    "    X_train = scaler.transform(X_train)  # doctest: +SKIP\n",
    "    X_test = scaler.transform(X_test) \n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "    corr_features = correlation(X_train, 0.8)\n",
    "    X_train.drop(labels=corr_features, axis=1, inplace=True)\n",
    "    X_test.drop(labels=corr_features, axis=1, inplace=True)\n",
    "    clf.fit(X_train, y_train[y_train.columns[i:i+1]])\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_predict = pd.DataFrame(y_pred)\n",
    "    #macro_roc_auc_ovo = multiclass_roc_auc_score(y_test[y_test.columns[i:i+1]],y_predict)\n",
    "    #print(macro_roc_auc_ovo)\n",
    "    print(accuracy_score(y_test[y_test.columns[i:i+1]],y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48865546218487393\n",
      "0.36470588235294116\n",
      "0.5033613445378151\n",
      "0.5903361344537815\n",
      "0.3871848739495798\n",
      "0.5327731092436975\n",
      "0.38802521008403357\n",
      "0.8172268907563025\n",
      "0.32815126050420174\n",
      "0.45336134453781507\n",
      "0.6716386554621848\n",
      "0.3867647058823529\n",
      "0.5109243697478991\n",
      "0.6487394957983192\n",
      "0.6415966386554621\n",
      "0.6852941176470588\n",
      "0.51890756302521\n",
      "0.3058823529411765\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "threshold = 0.6\n",
    "from sklearn.preprocessing import StandardScaler  # doctest: +SKIP\n",
    "from sklearn.model_selection import KFold \n",
    "kf = KFold(4,True,4) \n",
    "clf = RandomForestClassifier( random_state= 10,max_features=10, n_estimators= 100, max_depth=9, criterion='entropy')\n",
    "for i in range(len(y_df.columns)):\n",
    "    selector = SelectFdr(chi2, alpha =9.0)\n",
    "    X_new = selector.fit_transform(x_df,  y_df[y_df.columns[i:i+1]])\n",
    "    X = pd.DataFrame(X_new)\n",
    "    summ =0\n",
    "    count =0\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        count = count+1\n",
    "        X_train, X_test = X.loc[train_index], X.loc[val_index]\n",
    "        y_train, y_test = y_df.loc[train_index], y_df.loc[val_index]\n",
    "        \n",
    "        scaler = StandardScaler()  # doctest: +SKIP\n",
    "        scaler.fit(X_train)  # doctest: +SKIP\n",
    "        X_train = scaler.transform(X_train)  # doctest: +SKIP\n",
    "        X_test = scaler.transform(X_test) \n",
    "        X_train = pd.DataFrame(X_train)\n",
    "        X_test = pd.DataFrame(X_test)\n",
    "        corr_features = correlation(X_train, 0.8)\n",
    "        X_train.drop(labels=corr_features, axis=1, inplace=True)\n",
    "        X_test.drop(labels=corr_features, axis=1, inplace=True)\n",
    "        clf.fit(X_train, y_train[y_train.columns[i:i+1]])\n",
    "        y_pred = clf.predict(X_test)\n",
    "        y_predict = pd.DataFrame(y_pred)\n",
    "        #macro_roc_auc_ovo = multiclass_roc_auc_score(y_test[y_test.columns[i:i+1]],y_predict)\n",
    "        #print(macro_roc_auc_ovo)\n",
    "        summ = summ + accuracy_score(y_test[y_test.columns[i:i+1]],y_predict)\n",
    "    print(summ/count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=6)]: Done  97 out of 108 | elapsed:    8.5s remaining:    1.0s\n",
      "[Parallel(n_jobs=6)]: Done 108 out of 108 | elapsed:    8.6s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6071428571428571\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 108 out of 108 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42857142857142855\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 108 out of 108 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4642857142857143\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 108 out of 108 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6071428571428571\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 108 out of 108 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39285714285714285\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 108 out of 108 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5714285714285714\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 108 out of 108 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4642857142857143\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 108 out of 108 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9642857142857143\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 108 out of 108 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32142857142857145\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 108 out of 108 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39285714285714285\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done  42 out of 108 | elapsed:    0.9s remaining:    1.4s\n",
      "[Parallel(n_jobs=6)]: Done 108 out of 108 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8214285714285714\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 108 out of 108 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42857142857142855\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 108 out of 108 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42857142857142855\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 108 out of 108 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6428571428571429\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 108 out of 108 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7142857142857143\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 108 out of 108 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6071428571428571\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 108 out of 108 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35714285714285715\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "0.6071428571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 108 out of 108 | elapsed:    1.7s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "threshold = 0.6\n",
    "from sklearn.preprocessing import StandardScaler  # doctest: +SKIP\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100],\n",
    "    'max_features': [2, 8, 10, 7],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "#     'min_samples_split': [8, 10, 12],\n",
    "#     'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "clf = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = 6, verbose = 2)\n",
    "#clf = RandomForestClassifier(random_state=20, max_features=10, n_estimators= 100, max_depth=7, criterion='entropy')\n",
    "for i in range(len(y_df.columns)):\n",
    "    \n",
    "    selector = SelectFdr(chi2, alpha =11.0)\n",
    "    X_new = selector.fit_transform(x_df,  y_df[y_df.columns[i:i+1]])\n",
    "    X = pd.DataFrame(X_new)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_df, test_size=0.2, random_state=42)\n",
    "    scaler = StandardScaler()  # doctest: +SKIP\n",
    "    scaler.fit(X_train)  # doctest: +SKIP\n",
    "    X_train = scaler.transform(X_train)  # doctest: +SKIP\n",
    "    X_test = scaler.transform(X_test) \n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "    corr_features = correlation(X_train, 0.8)\n",
    "    X_train.drop(labels=corr_features, axis=1, inplace=True)\n",
    "    X_test.drop(labels=corr_features, axis=1, inplace=True)\n",
    "    clf.fit(X_train, y_train[y_train.columns[i:i+1]])\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_predict = pd.DataFrame(y_pred)\n",
    "    #macro_roc_auc_ovo = multiclass_roc_auc_score(y_test[y_test.columns[i:i+1]],y_predict)\n",
    "    #print(macro_roc_auc_ovo)\n",
    "    print(accuracy_score(y_test[y_test.columns[i:i+1]],y_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.6071428571428571\n",
    "0.42857142857142855\n",
    "0.4642857142857143\n",
    "0.6071428571428571\n",
    "0.39285714285714285\n",
    "0.5714285714285714\n",
    "0.4642857142857143\n",
    "0.9642857142857143\n",
    "0.32142857142857145\n",
    "0.39285714285714285\n",
    "0.8214285714285714\n",
    "0.42857142857142855\n",
    "0.42857142857142855\n",
    "0.6428571428571429\n",
    "0.7142857142857143\n",
    "0.6071428571428571\n",
    "0.35714285714285715\n",
    "0.6071428571428571"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
