{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech Emotion Recognition - Signal Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this notebook is to set up all speech emotion recognition preprocessing for the time distributed ConvNet. \n",
    "\n",
    "The data set used for training is the **RAVDESS** data set \n",
    "The signal preprocessing include :\n",
    "- Signal discretization\n",
    "- Audio data augmentation\n",
    "- Log-mel-spectrogram extraction\n",
    "- Time distributed framing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  General import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T16:29:23.010808Z",
     "start_time": "2019-05-21T16:29:19.571354Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pickle\n",
    "import itertools\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import librosa\n",
    "import IPython\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T16:38:44.580314Z",
     "start_time": "2018-12-04T16:38:44.560062Z"
    }
   },
   "source": [
    "## Set labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T16:29:23.018183Z",
     "start_time": "2019-05-21T16:29:23.013273Z"
    }
   },
   "outputs": [],
   "source": [
    "# RAVDESS labels\n",
    "label_dict_ravdess = {'02': 'NEU', '03':'HAP', '04':'SAD', '05':'ANG', '06':'FEA', '07':'DIS', '08':'SUR'}\n",
    "\n",
    "# Differentiating genders for labelling\n",
    "def set_label_ravdess(audio_file, gender_differentiation):\n",
    "    label = label_dict_ravdess.get(audio_file[6:-16])\n",
    "    if gender_differentiation == True:\n",
    "        if int(audio_file[18:-4])%2 == 0: # Female\n",
    "            label = 'f_' + label\n",
    "        if int(audio_file[18:-4])%2 == 1: # Male\n",
    "            label = 'm_' + label\n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T16:31:42.869915Z",
     "start_time": "2019-05-21T16:29:23.020121Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start feature extraction\n",
    "print(\"Import Data: START\")\n",
    "\n",
    "# Audio file path and names\n",
    "file_path = '../RAVDESS/'\n",
    "file_names = os.listdir(file_path)\n",
    "\n",
    "# Initialize features and labels list\n",
    "signal = []\n",
    "labels = []\n",
    "\n",
    "sample_rate = 16000     \n",
    "max_pad_len = 49100\n",
    "\n",
    "# Compute spectogram for all audio file\n",
    "for audio_index, audio_file in enumerate(file_names):\n",
    "    if audio_file[6:-16] in list(label_dict_ravdess.keys()):\n",
    "        # Read audio file\n",
    "        y, sr = librosa.core.load(file_path + audio_file, sr=sample_rate, offset=0.5)\n",
    "        y = zscore(y)\n",
    "        if len(y) < max_pad_len:    \n",
    "            y_padded = np.zeros(max_pad_len)\n",
    "            y_padded[:len(y)] = y\n",
    "            y = y_padded\n",
    "        elif len(y) > max_pad_len:\n",
    "            y = np.asarray(y[:max_pad_len])\n",
    "        signal.append(y)\n",
    "        labels.append(set_label_ravdess(audio_file, False))\n",
    "        \n",
    "# Cast labels to array\n",
    "labels = np.asarray(labels).ravel()\n",
    "\n",
    "# Stop feature extraction\n",
    "print(\"Import Data: END \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add features from the signal array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T16:31:43.048012Z",
     "start_time": "2019-05-21T16:31:43.043368Z"
    }
   },
   "outputs": [],
   "source": [
    "# Number of augmented data\n",
    "nb_augmented = 2\n",
    "\n",
    "# Function to add noise to a signals with a desired Signal Noise ratio (SNR)\n",
    "def noisy_signal(signal, snr_low=15, snr_high=30, nb_augmented=2):\n",
    "    signal_len = len(signal)\n",
    "    noise = np.random.normal(size=(nb_augmented, signal_len))\n",
    "    s_power = np.sum((signal / (2.0 ** 15)) ** 2) / signal_len\n",
    "    n_power = np.sum((noise / (2.0 ** 15)) ** 2, axis=1) / signal_len\n",
    "    snr = np.random.randint(snr_low, snr_high)\n",
    "    K = np.sqrt((s_power / n_power) * 10 ** (- snr / 10))\n",
    "    K = np.ones((signal_len, nb_augmented)) * K\n",
    "    \n",
    "    return signal + K.T * noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T16:31:48.009729Z",
     "start_time": "2019-05-21T16:31:43.049711Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate noisy signals from signal list\n",
    "print(\"Data Augmentation: START\")\n",
    "augmented_signal = list(map(noisy_signal, signal))\n",
    "print(\"Data Augmentation: END!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T17:10:51.478413Z",
     "start_time": "2018-12-04T17:10:51.475113Z"
    }
   },
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T16:31:48.312940Z",
     "start_time": "2019-05-21T16:31:48.308691Z"
    }
   },
   "outputs": [],
   "source": [
    "def mel_spectrogram(y, sr=16000, n_fft=512, win_length=256, hop_length=128, window='hamming', n_mels=128, fmax=4000):\n",
    "    \n",
    "    # Compute spectogram\n",
    "    mel_spect = np.abs(librosa.stft(y, n_fft=n_fft, window=window, win_length=win_length, hop_length=hop_length)) ** 2\n",
    "    \n",
    "    # Compute mel spectrogram\n",
    "    mel_spect = librosa.feature.melspectrogram(S=mel_spect, sr=sr, n_mels=n_mels, fmax=fmax)\n",
    "    \n",
    "    # Compute log-mel spectrogram\n",
    "    mel_spect = librosa.power_to_db(mel_spect, ref=np.max)\n",
    "    \n",
    "    return mel_spect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T16:32:06.530587Z",
     "start_time": "2019-05-21T16:31:48.314692Z"
    }
   },
   "outputs": [],
   "source": [
    "# Start feature extraction\n",
    "print(\"Feature extraction: START\")\n",
    "\n",
    "# Compute spectogram for all audio file\n",
    "mel_spect = np.asarray(list(map(mel_spectrogram, signal)))\n",
    "augmented_mel_spect = [np.asarray(list(map(mel_spectrogram, augmented_signal[i]))) for i in range(len(augmented_signal))]\n",
    "\n",
    "# Stop feature extraction\n",
    "print(\"Feature extraction: END!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T16:32:06.872643Z",
     "start_time": "2019-05-21T16:32:06.533176Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot one random Spectogram \n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(mel_spect[np.random.randint(len(mel_spect))], origin='lower', aspect='auto', cmap='viridis')\n",
    "plt.title('Log-Mel Spectrogram of an audio file', fontsize=26)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T16:32:09.304749Z",
     "start_time": "2019-05-21T16:32:06.874812Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build Train and test dataset\n",
    "MEL_SPECT_train, MEL_SPECT_test, AUG_MEL_SPECT_train, AUG_MEL_SPECT_test, label_train, label_test = train_test_split(mel_spect, augmented_mel_spect, labels, test_size=0.2)\n",
    "aug_label_train = np.asarray(list(itertools.chain.from_iterable([[label] * nb_augmented for label in label_train])))\n",
    "AUG_MEL_SPECT_train = np.asarray(list(itertools.chain.from_iterable(AUG_MEL_SPECT_train)))\n",
    "\n",
    "# Concatenate original and augmented\n",
    "X_train = np.concatenate((MEL_SPECT_train, AUG_MEL_SPECT_train))\n",
    "y_train = np.concatenate((label_train, aug_label_train))\n",
    "\n",
    "# Build test set\n",
    "X_test = MEL_SPECT_test\n",
    "y_test = label_test\n",
    "\n",
    "del MEL_SPECT_train, AUG_MEL_SPECT_train, label_train, aug_label_train, AUG_MEL_SPECT_test, MEL_SPECT_test, label_test\n",
    "del mel_spect, augmented_mel_spect, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time distributed framing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T16:32:13.861389Z",
     "start_time": "2019-05-21T16:32:09.306396Z"
    }
   },
   "outputs": [],
   "source": [
    "# Time distributed parameters\n",
    "win_ts = 128\n",
    "hop_ts = 64\n",
    "\n",
    "# Split spectrogram into frames\n",
    "def frame(x, win_step=128, win_size=64):\n",
    "    nb_frames = 1 + int((x.shape[2] - win_size) / win_step)\n",
    "    frames = np.zeros((x.shape[0], nb_frames, x.shape[1], win_size)).astype(np.float32)\n",
    "    for t in range(nb_frames):\n",
    "        frames[:,t,:,:] = np.copy(x[:,:,(t * win_step):(t * win_step + win_size)]).astype(np.float32)\n",
    "    return frames\n",
    "\n",
    "# Frame for TimeDistributed model\n",
    "X_train = frame(X_train, hop_ts, win_ts)\n",
    "X_test = frame(X_test, hop_ts, win_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T16:32:16.173921Z",
     "start_time": "2019-05-21T16:32:13.863202Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save Train and test set\n",
    "pickle.dump(X_train.astype(np.float16), open('../Pickle/RAVDESS/DIS/[RAVDESS][MEL_SPECT][X_train].p', 'wb'))\n",
    "pickle.dump(y_train, open('../Pickle/RAVDESS/DIS/[RAVDESS][MEL_SPECT][y_train].p', 'wb'))\n",
    "pickle.dump(X_test.astype(np.float16), open('../Pickle/RAVDESS/DIS/[RAVDESS][MEL_SPECT][X_test].p', 'wb'))\n",
    "pickle.dump(y_test, open('../Pickle/RAVDESS/DIS/[RAVDESS][MEL_SPECT][y_test].p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
